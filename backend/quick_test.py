"""
Quick test for Diario Oficial scraper
- Tests only 1 date (yesterday)
- 60 second total timeout
- Debug mode by default (visible browser)
- Detailed logs at each step
"""
import asyncio
import os
import argparse
from datetime import datetime, timedelta
import sys

# Fix encoding for Windows console
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

sys.path.append(os.path.join(os.getcwd(), 'backend'))

from scraper_service import DiarioScraper

async def quick_test(headless=False):
    debug_mode = not headless
    scraper = DiarioScraper(debug=debug_mode)
    
    yesterday = (datetime.now() - timedelta(days=1)).strftime("%d/%m/%Y")
    
    print("=" * 70)
    print("üöÄ TESTE R√ÅPIDO DO SCRAPER")
    print("=" * 70)
    print(f"üìÖ Data: {yesterday}")
    print(f"üîß Modo: {'HEADLESS (invis√≠vel)' if headless else 'DEBUG (vis√≠vel)'}")
    print(f"‚è±Ô∏è  Timeout: 60 segundos")
    print("=" * 70)
    print()
    
    async def log(msg):
        timestamp = datetime.now().strftime("%H:%M:%S")
        try:
            print(f"[{timestamp}] {msg}")
        except UnicodeEncodeError:
            print(f"[{timestamp}] {msg.encode('ascii', 'ignore').decode('ascii')}")
    
    try:
        start_time = datetime.now()
        
        # Total timeout of 60 seconds
        results = await asyncio.wait_for(
            scraper.scrape(yesterday, yesterday, [], status_callback=log),
            timeout=60
        )
        
        elapsed = (datetime.now() - start_time).total_seconds()
        
        print()
        print("=" * 70)
        print(f"‚úÖ SUCESSO!")
        print(f"‚è±Ô∏è  Tempo total: {elapsed:.1f} segundos")
        print(f"üìä Resultados: {len(results)}")
        print("=" * 70)
        
        if results:
            print("\nüìÑ Amostra dos resultados:")
            for i, r in enumerate(results[:3], 1):
                print(f"\n{i}. Termo: {r.term}")
                print(f"   Processo: {r.process_number}")
                print(f"   Documento: {r.document_id}")
                print(f"   Resumo: {r.summary[:80]}...")
        else:
            print("\n‚ö†Ô∏è  Nenhuma publica√ß√£o encontrada")
            print("üí° Isso pode ser normal se n√£o houver publica√ß√µes relevantes")
        
        return True
        
    except asyncio.TimeoutError:
        elapsed = (datetime.now() - start_time).total_seconds()
        print()
        print("=" * 70)
        print(f"‚ùå TIMEOUT ap√≥s {elapsed:.1f} segundos")
        print("=" * 70)
        print("\nüí° Poss√≠veis causas:")
        print("   1. Site do Di√°rio Oficial est√° lento/fora do ar")
        print("   2. Conex√£o de internet inst√°vel")
        print("   3. Anti-bot bloqueando acesso automatizado")
        print("\nüîß Tente:")
        print("   - Rodar novamente ap√≥s alguns minutos")
        print("   - Verificar se o site est√° acess√≠vel no navegador normal")
        print("   - Usar modo debug para ver onde trava: python quick_test.py")
        return False
        
    except Exception as e:
        print()
        print("=" * 70)
        print(f"‚ùå ERRO: {e}")
        print("=" * 70)
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Teste r√°pido do scraper')
    parser.add_argument('--headless', action='store_true', 
                       help='Executar em modo headless (padr√£o √© debug/vis√≠vel)')
    args = parser.parse_args()
    
    success = asyncio.run(quick_test(headless=args.headless))
    sys.exit(0 if success else 1)
